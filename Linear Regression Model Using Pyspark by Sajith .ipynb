{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set environment\n",
    "import os\n",
    "import sys\n",
    " \n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/local/anaconda/bin/python\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/local/anaconda/bin/python\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.4-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Sparksession driver\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Classification of Medical Cost Prediction Dataset\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+------+--------+------+----------------+----------------+----------------+----------------+-----------+\n",
      "| _c0|age|sex|   bmi|children|smoker|region_southwest|region_southeast|region_northwest|region_northeast|    charges|\n",
      "+----+---+---+------+--------+------+----------------+----------------+----------------+----------------+-----------+\n",
      "| 629| 44|  0| 38.95|       0|     1|             0.0|             0.0|             1.0|             0.0| 42983.4585|\n",
      "|1087| 57|  1| 31.54|       0|     0|             0.0|             0.0|             1.0|             0.0| 11353.2276|\n",
      "| 283| 55|  0|32.395|       1|     0|             0.0|             0.0|             0.0|             1.0|11879.10405|\n",
      "| 790| 39|  0|  41.8|       0|     0|             0.0|             1.0|             0.0|             0.0|   5662.225|\n",
      "| 594| 41|  1| 40.26|       0|     0|             0.0|             1.0|             0.0|             0.0|  5709.1644|\n",
      "| 579| 25|  0|23.465|       0|     0|             0.0|             0.0|             0.0|             1.0| 3206.49135|\n",
      "| 478| 21|  1| 36.85|       0|     0|             0.0|             1.0|             0.0|             0.0|  1534.3045|\n",
      "| 255| 55|  0|25.365|       3|     0|             0.0|             0.0|             0.0|             1.0|13047.33235|\n",
      "| 350| 57|  0| 23.18|       0|     0|             0.0|             0.0|             1.0|             0.0| 11830.6072|\n",
      "| 262| 52|  1| 24.32|       3|     1|             0.0|             0.0|             0.0|             1.0| 24869.8368|\n",
      "|  48| 60|  0| 24.53|       0|     0|             0.0|             1.0|             0.0|             0.0| 12629.8967|\n",
      "| 408| 38|  1| 21.12|       3|     0|             0.0|             1.0|             0.0|             0.0|  6652.5288|\n",
      "| 779| 53|  1| 28.88|       0|     0|             0.0|             0.0|             1.0|             0.0|  9869.8102|\n",
      "| 764| 45|  0|25.175|       2|     0|             0.0|             0.0|             0.0|             1.0| 9095.06825|\n",
      "| 194| 18|  1| 34.43|       0|     0|             0.0|             1.0|             0.0|             0.0|  1137.4697|\n",
      "| 341| 62|  1| 30.02|       0|     0|             0.0|             0.0|             1.0|             0.0| 13352.0998|\n",
      "|   3| 33|  1|22.705|       0|     0|             0.0|             0.0|             1.0|             0.0|21984.47061|\n",
      "| 298| 31|  1| 34.39|       3|     1|             0.0|             0.0|             1.0|             0.0| 38746.3551|\n",
      "| 304| 57|  0|  38.0|       2|     0|             1.0|             0.0|             0.0|             0.0|  12646.207|\n",
      "|1079| 63|  1| 33.66|       3|     0|             0.0|             1.0|             0.0|             0.0| 15161.5344|\n",
      "+----+---+---+------+--------+------+----------------+----------------+----------------+----------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('linear/regressionspark.csv',inferSchema=True,header = True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of cells in column _c0 with null values: 0\n",
      "no. of cells in column age with null values: 0\n",
      "no. of cells in column sex with null values: 0\n",
      "no. of cells in column bmi with null values: 0\n",
      "no. of cells in column children with null values: 0\n",
      "no. of cells in column smoker with null values: 0\n",
      "no. of cells in column region_southwest with null values: 0\n",
      "no. of cells in column region_southeast with null values: 0\n",
      "no. of cells in column region_northwest with null values: 0\n",
      "no. of cells in column region_northeast with null values: 0\n",
      "no. of cells in column charges with null values: 0\n"
     ]
    }
   ],
   "source": [
    "#Check for missing values\n",
    "for col in df.columns:\n",
    "    print(\"no. of cells in column\", col, \"with null values:\", df.filter(df[col].isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|            features|    charges|\n",
      "+--------------------+-----------+\n",
      "|(9,[0,2,4,7],[44....| 42983.4585|\n",
      "|(9,[0,1,2,7],[57....| 11353.2276|\n",
      "|(9,[0,2,3,8],[55....|11879.10405|\n",
      "|(9,[0,2,6],[39.0,...|   5662.225|\n",
      "|(9,[0,1,2,6],[41....|  5709.1644|\n",
      "+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#all the independent variables need to be packed into one column of vector type\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['age','sex','bmi','children','smoker','region_southwest','region_southeast','region_northwest','region_northeast'], \n",
    "                            outputCol=\"features\")\n",
    "feature_vec=assembler.transform(df).select('features','charges')\n",
    "feature_vec.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of cells in column features with null values: 0\n",
      "no. of cells in column charges with null values: 0\n"
     ]
    }
   ],
   "source": [
    "#Check for missing values\n",
    "for col in feature_vec.columns:\n",
    "    print(\"no. of cells in column\", col, \"with null values:\", feature_vec.filter(feature_vec[col].isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_data, test_data = feature_vec.randomSplit([.75,.25],seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = feature_vec.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [253.05498418182162,-155.79514553237914,359.5991811521862,483.3759688907996,23287.34168382452,68.4021813272167,-357.13817518769883,822.0804352816368,1150.334172762263]\n",
      "Intercept: -13337.467377907313\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='charges', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.ml.regression.LinearRegressionTrainingSummary object at 0x7f1317587978>\n",
      "RMSE: 6046.109848\n",
      "r2 for Training: 0.746519\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lr_model.summary\n",
    "print(trainingSummary)\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2 for Training: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, charges: double, prediction: double]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_predictions = lr_model.transform(test_df)\n",
    "lr_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+--------------------+\n",
      "|         prediction| charges|            features|\n",
      "+-------------------+--------+--------------------+\n",
      "|-1496.7518558445754|1241.565|(9,[0,1,2,5],[19....|\n",
      "|-1316.9522652684846| 1242.26|(9,[0,1,2,5],[19....|\n",
      "|  2314.999464368595|1256.299|(9,[0,1,2,5],[19....|\n",
      "|  4112.995370129527|1263.249|(9,[0,1,2,5],[19....|\n",
      "|  6346.516965398954|1682.597|(9,[0,1,2,5],[22....|\n",
      "+-------------------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.757428\n"
     ]
    }
   ],
   "source": [
    "lr_predictions = lr_model.transform(test_df)\n",
    "lr_predictions.select(\"prediction\",\"charges\",\"features\").show(5)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"charges\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 6046.109847952787\n",
      "R2: 0.7465186054173145\n"
     ]
    }
   ],
   "source": [
    "# Get the RMSE\n",
    "print(\"RMSE: {0}\".format(lr_model.summary.rootMeanSquaredError))\n",
    "# Get the R2\n",
    "print(\"R2: {0}\".format(lr_model.summary.r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
